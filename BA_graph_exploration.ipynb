{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import networkx as nx\n",
    "from pysad.pysad.NodeInfo import NodeInfo, SynthNodeInfo\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import pysad\n",
    "#import pysad.utils\n",
    "import pysad.pysad.collect as collect\n",
    "import pysad.pysad.synthesis as synthesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../synthesis/'\n",
    "graphname = 'Barabasi-Albert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = 1000\n",
    "edges_per_node = 2\n",
    "G = nx.barabasi_albert_graph(nodes, edges_per_node)\n",
    "G.graph['name'] = graphname\n",
    "graph_handle = synthesis.SyntheticNetwork(G)\n",
    "graph_handle.rules['min_degree'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exploration_depth = 5\n",
    "total_node_list, total_nodes_df, total_edges_df, info_acc = collect.spiky_ball([20], graph_handle, \n",
    "                                                                            exploration_depth=exploration_depth,\n",
    "                                                                            mode='constant', random_subset_size=2,\n",
    "                                                                            spread_type='broad', \n",
    "                                                                            node_acc=SynthNodeInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of nodes in the spiky ball:',len(total_node_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysad.pysad.graph as graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_df, edge_df = total_nodes_df, total_edges_df\n",
    "node_df = synthesis.reshape_node_data(node_df)\n",
    "edge_df = synthesis.reshape_edge_data(edge_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_WEIGHT = 0\n",
    "MIN_DEGREE = 1 # Minimal number of connections in the graph\n",
    "\n",
    "# Write spiky ball info on the graph\n",
    "G = graph.add_edges_attributes(G,edge_df)\n",
    "G = graph.add_node_attributes(G,node_df)\n",
    "\n",
    "# create the spiky ball graph (option)\n",
    "Gsp = graph.graph_from_edgeslist(edge_df, MIN_WEIGHT)\n",
    "Gsp = graph.add_edges_attributes(Gsp,edge_df)\n",
    "Gsp = graph.add_node_attributes(Gsp,node_df)\n",
    "Gsp = graph.reduce_graph(Gsp,MIN_DEGREE)\n",
    "Gsp = graph.handle_spikyball_neighbors(Gsp,graph_handle,remove=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the graph\n",
    "import networkx as nx\n",
    "import json\n",
    "# Save as gexf file\n",
    "graphfilename = data_path + graphname + '.gexf'\n",
    "nx.write_gexf(G,graphfilename)\n",
    "print('Wrote',graphfilename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics of propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.diameter(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ball_test(graph_handle,params):\n",
    "    node_dic = {}\n",
    "    for it in range(params['nb_iter']):\n",
    "        total_node_list, total_nodes_df, total_edges_df, node_acc = collect.spiky_ball([params['initial_node']], \n",
    "                                                                               graph_handle, \n",
    "                                                                               exploration_depth=params['exploration_depth'],\n",
    "                                                                               mode='percent',\n",
    "                                                                               random_subset_size=params['random_subset_size'],\n",
    "                                                                                  spread_type='sharp', node_acc=SynthNodeInfo())\n",
    "        for node in total_node_list:\n",
    "            if node in node_dic:\n",
    "                node_dic[node] += 1 \n",
    "            else:\n",
    "                node_dic[node] = 1\n",
    "\n",
    "    # delete the initial node (always in the list)\n",
    "    del node_dic[params['initial_node']] \n",
    "    return node_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'nb_iter' : 4, 'exploration_depth' : 10,\n",
    "            'initial_node' : 20, 'random_subset_size' : 0.1}\n",
    "node_dic1 = ball_test(graph_handle,params)\n",
    "# dictionary with each node as key and its degree as value\n",
    "degree_dic1 = dict(G.degree(node_dic1.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'nb_iter' : 4, 'exploration_depth' : 4,\n",
    "            'initial_node' : 20, 'random_subset_size' : 1}\n",
    "node_dic2 = ball_test(graph_handle,params)\n",
    "# dictionary with each node as key and its degree as value\n",
    "degree_dic2 = dict(G.degree(node_dic2.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Degree distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaged over iterations\n",
    "\n",
    "def expand_occurences(node_dic,degree_dic):\n",
    "    i = 0\n",
    "    av_dic = {}\n",
    "    for node,v in node_dic.items():\n",
    "        for n in range(v):\n",
    "            av_dic[i] = degree_dic[node]\n",
    "            i +=1\n",
    "    return av_dic\n",
    "\n",
    "av_dic1 = expand_occurences(node_dic1,degree_dic1)\n",
    "av_dic2 = expand_occurences(node_dic2,degree_dic2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### log-binning found there: https://stackoverflow.com/questions/16489655/plotting-log-binned-network-degree-distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_zeros(a_list):\n",
    "    return [i for i in a_list if i>0]\n",
    "\n",
    "def log_binning(counter_dict,bin_count=35):\n",
    "\n",
    "    max_x = np.log10(max(counter_dict.keys()))\n",
    "    max_y = np.log10(max(counter_dict.values()))\n",
    "    max_base = max([max_x,max_y])\n",
    "\n",
    "    min_x = np.log10(min(drop_zeros(counter_dict.keys())))\n",
    "\n",
    "    bins = np.logspace(min_x,max_base,num=bin_count)\n",
    "\n",
    "    # Based off of: http://stackoverflow.com/questions/6163334/binning-data-in-python-with-scipy-numpy\n",
    "    bin_means_y = (np.histogram(list(counter_dict.keys()),bins,weights=list(counter_dict.values()))[0] /\n",
    "                   np.histogram(list(counter_dict.keys()),bins)[0])\n",
    "    bin_means_x = (np.histogram(list(counter_dict.keys()),bins,weights=list(counter_dict.keys()))[0] /\n",
    "                   np.histogram(list(counter_dict.keys()),bins)[0])\n",
    "\n",
    "    return bin_means_x,bin_means_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def degree_distribution(degree_dic, mode='log', density=True):\n",
    "    #ba_c = nx.degree_centrality(ba_g)\n",
    "\n",
    "    count_dic = dict(Counter(degree_dic.values()))\n",
    "\n",
    "    if mode == 'lin':    # linear bins\n",
    "        dd_x,dd_y = list(count_dic.keys()),list(count_dic.values())\n",
    "    elif mode == 'log':# log bins\n",
    "        dd_x,dd_y = log_binning(count_dic,20)\n",
    "    else:\n",
    "        raise('Unknown mode, use mode=\"lin\" or mode=\"log\".')\n",
    "    \n",
    "    if density == True: # normalize\n",
    "        dd_y = [v / len(degree_dic) for v in dd_y]\n",
    "    return dd_x,dd_y  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "lin_x,lin_y = degree_distribution(av_dic1, mode='lin')\n",
    "#plt.scatter(lin_x,lin_y,c='r',marker='x',s=10)\n",
    "log_x,log_y = degree_distribution(av_dic1, mode='log',density=True)\n",
    "plt.scatter(log_x,log_y,c='r',marker='.',s=100,label='spiky')\n",
    "lin_x,lin_y = degree_distribution(av_dic2, mode='lin')\n",
    "#plt.scatter(lin_x,lin_y,c='b',marker='x',s=10)\n",
    "log_x,log_y = degree_distribution(av_dic2, mode='log',density=True)\n",
    "plt.scatter(log_x,log_y,c='b',marker='.',s=100,label='snowy')\n",
    "#plt.xlim((1e-4,1e-1))\n",
    "#plt.ylim((.9,1e4))\n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Degree distribution of spiky and snow balls')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Degree stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dic = {}\n",
    "nb_iter = 100 # ?\n",
    "for it in range(nb_iter):\n",
    "    n_list = [node for node,val in node_dic1.items() if val == it]\n",
    "    degree_list = [degree_dic1[node] for node in n_list]\n",
    "    if degree_list:\n",
    "        count_dic[it] = degree_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_size = len(count_dic.keys())\n",
    "x = np.zeros((1,match_size))\n",
    "x_mean = np.zeros((1,match_size))\n",
    "x_std = np.zeros((1,match_size))\n",
    "for idx,(nb_match,degrees) in enumerate(count_dic.items()):\n",
    "    x[0,idx] = nb_match\n",
    "    x_mean[0,idx] = np.mean(np.array(degrees))\n",
    "    x_std[0,idx] = np.std(np.array(degrees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(x[0],x_mean[0], x_std[0], linestyle='None', marker='^')\n",
    "plt.xlabel('Nb of visits')\n",
    "plt.ylabel('Degree (mean and deviation)')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for idx in range(1,max(count_dic.keys())+1):\n",
    "    if idx in count_dic:\n",
    "        data.append(count_dic[idx])\n",
    "    else:\n",
    "        data.append(np.array([0]))\n",
    "#data = [v for k,v in count_dic.items()]\n",
    "fig7, ax7 = plt.subplots()\n",
    "ax7.set_title('Multiple Samples with Different sizes')\n",
    "ax7.boxplot(data)\n",
    "ax7.set(ylim=(0, 100))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=data)\n",
    "plt.ylim(0,90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visits vs degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def degrees_visits(node_dic,degree_dic):\n",
    "    match_size = len(node_dic.keys())\n",
    "    visits = np.zeros((1,match_size))\n",
    "    degrees = np.zeros((1,match_size))\n",
    "    for idx,node in enumerate(node_dic):\n",
    "        visits[0,idx] = node_dic[node]\n",
    "        degrees[0,idx] = degree_dic[node]\n",
    "    return degrees, visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees1,visits1 = degrees_visits(node_dic1, degree_dic1)\n",
    "degrees2,visits2 = degrees_visits(node_dic2, degree_dic2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.scatter(degrees1,visits1/nb_iter)\n",
    "plt.scatter(degrees2,visits2/nb_iter)\n",
    "#plt.xscale('log')\n",
    "#plt.yscale('log')\n",
    "plt.xlabel('Degrees')\n",
    "plt.ylabel('Ratio of visits')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(degrees1,visits1/nb_iter)\n",
    "plt.xscale('log')\n",
    "#plt.yscale('log')\n",
    "plt.xlabel('Degrees')\n",
    "plt.ylabel('Ratio of visits')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## appearance wrt degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees_list = []\n",
    "for node in node_dic1:\n",
    "    for occur in range(degree_dic1[node]):\n",
    "        degree_list.append(degree_dic1[node])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log-scaled bins\n",
    "bins = np.logspace(1, 2, 50)\n",
    "widths = (bins[1:] - bins[:-1])\n",
    "\n",
    "plt.hist(degree_list,bins=bins)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Degree')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
